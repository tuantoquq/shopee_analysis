version: "3"
services:
  # # HADOOP
  # namenode:
  #   image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
  #   container_name: namenode
  #   restart: always
  #   ports:
  #     - 9870:9870
  #     - 9000:9000
  #   volumes:
  #     - hadoop_namenode:/hadoop/dfs/name
  #   environment:
  #     - CLUSTER_NAME=test
  #   env_file:
  #     - ./hadoop/hadoop.env
  #   networks:
  #     project3-network:
  #       ipv4_address: 172.25.0.2

  # datanode:
  #   image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
  #   container_name: datanode
  #   restart: always
  #   ports:
  #     - 9864:9864
  #   volumes:
  #     - hadoop_datanode:/hadoop/dfs/data
  #   environment:
  #     SERVICE_PRECONDITION: "namenode:9870"
  #   env_file:
  #     - ./hadoop/hadoop.env
  #   networks:
  #     project3-network:
  #       ipv4_address: 172.25.0.3
  
  # resourcemanager:
  #   image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
  #   container_name: resourcemanager
  #   restart: always
  #   ports:
  #     - 8088:8088
  #   environment:
  #     SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864"
  #   env_file:
  #     - ./hadoop/hadoop.env
  #   networks:
  #     project3-network:
  #       ipv4_address: 172.25.0.4

  # nodemanager1:
  #   image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
  #   container_name: nodemanager
  #   restart: always
  #   ports:
  #     - 8042:8042
  #   environment:
  #     SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
  #   env_file:
  #     - ./hadoop/hadoop.env
  #   networks:
  #     project3-network:
  #       ipv4_address: 172.25.0.5
  
  # historyserver:
  #   image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8
  #   container_name: historyserver
  #   restart: always
  #   ports:
  #     - 8188:8188
  #   environment:
  #     SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
  #   volumes:
  #     - hadoop_historyserver:/hadoop/yarn/timeline
  #   env_file:
  #     - ./hadoop/hadoop.env
  #   networks:
  #     project3-network:
  #       ipv4_address: 172.25.0.6
  # #    # ZOOKEEPER
  # # zookeeper:
  # #   image: 'bitnami/zookeeper:3'
  # #   user: root
  # #   container_name: zookeeper-container
  # #   ports:
  # #     - '2181:2181'
  # #   environment:
  # #     - ALLOW_ANONYMOUS_LOGIN=yes
  # #   networks:
  # #     project3-network:
  # #       ipv4_address: 172.25.0.7
  # # # KAFKA
  # # kafka:
  # #   image: 'bitnami/kafka'
  # #   user: root
  # #   container_name: kafka-container
  # #   hostname: kafka
  # #   ports:
  # #     - '9092:9092'
  # #   environment:
  # #     - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
  # #     - ALLOW_PLAINTEXT_LISTENER=yes
  # #     - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
  # #     - KAFKA_CFG_LISTENERS=PLAINTEXT://:29092,PLAINTEXT_HOST://:9092
  # #     - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:29092,PLAINTEXT_HOST://kafka-container:9092
  # #   networks:
  # #     project3-network:
  # #       ipv4_address: 172.25.0.8
  # #   depends_on:
  # #     - zookeeper
  # zookeeper:
  #   image: zookeeper:3.4.9
  #   hostname: zookeeper
  #   container_name: zookeeper-container
  #   ports:
  #     - "2181:2181"
  #   environment:
  #     ZOO_MY_ID: 1
  #     ZOO_PORT: 2181
  #     ZOO_SERVERS: server.1=zookeeper:2888:3888
  #   volumes:
  #     - ./zookeeper/data:/data
  #     - ./zookeeper/datalog:/datalog
  #   networks:
  #     project3-network:
  #       ipv4_address: 172.25.0.7
  # kafka1:
  #   image: confluentinc/cp-kafka:5.3.0      #  offical 
  #   hostname: kafka1
  #   container_name: kafka-container
  #   ports:
  #     - "9092:9092"
  #   environment:
  #     KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka1:19092,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092
  #     KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
  #     KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
  #     KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
  #     KAFKA_BROKER_ID: 1
  #     KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
  #   volumes:
  #     - ./kafka/data:/var/lib/kafka/data
  #   depends_on:
  #     - zookeeper
  #   networks:
  #     project3-network:
  #       ipv4_address: 172.25.0.8
  # # SPARK
  # spark-master:
  #   container_name: spark-master
  #   hostname: spark
  #   image: bitnami/spark:3
  #   user: root
  #   environment:
  #     - SPARK_MODE=master
  #     - SPARK_MASTER=spark://spark-master:7077
  #     - MASTER=spark://spark-master:7077
  #     - SPARK_RPC_AUTHENTICATION_ENABLED=no
  #     - SPARK_RPC_ENCRYPTION_ENABLED=no
  #     - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
  #     - SPARK_SSL_ENABLED=no
  #     - SPARK_MASTER_HOST=spark-master
    
  #   ports:
  #     - '8080:8080'
  #   networks:
  #     project3-network:
  #       ipv4_address: 172.25.0.9
  #   extra_hosts:
  #     - 'spark-master:0.0.0.0'
  # spark-worker:
  #   container_name: spark-worker
  #   hostname: spark
  #   image: bitnami/spark:3
  #   user: root
  #   depends_on:
  #     - spark-master
  #   environment:
  #     - SPARK_MODE=worker
  #     - SPARK_MASTER_URL=spark://spark-master:7077
  #     - SPARK_MASTER=spark://spark-master:7077
  #     - SPARK_MASTER_HOST=spark-master
  #     - MASTER=spark://spark-master:7077
  #     - SPARK_WORKER_MEMORY=4G
  #     - SPARK_WORKER_CORES=2
  #     - SPARK_RPC_AUTHENTICATION_ENABLED=no
  #     - SPARK_RPC_ENCRYPTION_ENABLED=no
  #     - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
  #     - SPARK_SSL_ENABLED=no
  #   ports:
  #     - '8081:8081'
  #   networks:
  #     project3-network:
  #       ipv4_address: 172.25.0.10
  elasticsearch:
    container_name: es-container
    image: docker.elastic.co/elasticsearch/elasticsearch:7.11.0
    environment:
      - xpack.security.enabled=false
      - "discovery.type=single-node"
    networks:
      project3-network:
        ipv4_address: 172.25.0.11
    ports:
      - 9200:9200
  kibana:
    container_name: kb-container
    image: docker.elastic.co/kibana/kibana:7.11.0
    environment:
      - ELASTICSEARCH_HOSTS=http://es-container:9200
    networks:
      project3-network:
        ipv4_address: 172.25.0.12
    depends_on:
      - elasticsearch
    ports:
      - 5601:5601
networks:
  project3-network:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.25.0.0/16

